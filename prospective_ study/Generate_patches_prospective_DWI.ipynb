{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Generate_patches_prospective_DWI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "iiuTGhgiEvEC"
      },
      "source": [
        "#This code is for generating x_train and y_train patches from prospective high b-value DWI for training DnCNN \n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import os\n",
        "import os.path\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "patch_size, stride = 40, 10\n",
        "aug_times =10\n",
        "#num_threads = 16  \n",
        "imx =[]\n",
        "imy =[]\n",
        "x_patches = []\n",
        "y_patches = []\n",
        "scales = [1, 0.9, 0.8, 0.7]\n",
        "\n",
        "def data_aug(img_data, mode=0):\n",
        "        if mode == 0:\n",
        "           return img_data\n",
        "        elif mode == 1:\n",
        "           return np.flipud(img_data)\n",
        "        elif mode == 2:\n",
        "           return np.rot90(img_data,axes=(0, 1))\n",
        "        elif mode == 3:\n",
        "           return np.flipud(np.rot90(img_data,axes=(0, 1)))\n",
        "        elif mode == 4:\n",
        "           return np.rot90(img_data, k=2,axes=(0, 1))\n",
        "        elif mode == 5:\n",
        "           return np.flipud(np.rot90(img_data, k=2,axes=(0, 1)))\n",
        "        elif mode == 6:\n",
        "           return np.rot90(img_data, k=3,axes=(0, 1))\n",
        "        elif mode == 7:\n",
        "           return np.flipud(np.rot90(img_data, k=3,axes=(0, 1)))\n",
        "    \n",
        "\n",
        "                    \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXFDye2L_I8o"
      },
      "source": [
        "# Read X_train\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"Path for high b-value DWI data\"):\n",
        "    #for filename in [f for f in filenames if f.endswith(\"b3000_avg1_full_128.nii\" )]:\n",
        "    #for filename in [f for f in filenames if f.endswith(\"b3000_avg2_full_128.nii\" )]:\n",
        "    for filename in [f for f in filenames if f.endswith(\"b3000_avg4_full_128.nii\" )]:\n",
        "        img_path=os.path.join(dirpath, filename)\n",
        "        img = nib.load(os.path.join(dirpath, filename))\n",
        "        img_data2 = np.array(img.get_data())          \n",
        "        print(img_data2.shape)\n",
        "        img_data2=img_data2.astype('float32')   \n",
        "\n",
        "        slice_total=img_data2.shape[2]\n",
        "        for num_slice in range(slice_total):\n",
        "            img_data2[:,:,num_slice]=img_data2[:,:,num_slice]\n",
        "            imgx_data=img_data2[:,:,num_slice]\n",
        "            imx.append(imgx_data)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0848iN2_YUn"
      },
      "source": [
        " # Read Y_train\n",
        "\n",
        " for dirpath, dirnames, filenames in os.walk(\".\"):\n",
        "     for filename in [f for f in filenames if f.endswith(\"b3000_avg10_full_128.nii\" )]:\n",
        "         img_path=os.path.join(dirpath, filename)\n",
        "         img = nib.load(os.path.join(dirpath, filename))\n",
        "         img_data2 = np.array(img.get_data())   \n",
        "         img_data2=img_data2.astype('float32')       \n",
        "         print(img_data2.shape)             \n",
        "         slice_total=img_data2.shape[2]\n",
        "         for num_slice in range(slice_total):\n",
        "             #global_thresh = threshold_otsu(img_data2[:,:,num_slice])\n",
        "            # binary_global = img_data2[:,:,num_slice] > global_thresh\n",
        "             img_data2[:,:,num_slice]=img_data2[:,:,num_slice]\n",
        "             imgy_data=img_data2[:,:,num_slice]\n",
        "          #if np.sum(imgy_data>45):\n",
        "             imy.append(imgy_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4CUgUp8--3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783c11f3-d034-4fcb-ae0b-1725c82ab8b9"
      },
      "source": [
        "# Scaling , data augmentantion and generate patches\n",
        "\n",
        "h, w = imgx_data.shape\n",
        "for num_slice in range(slice_total):\n",
        "    for s in scales:\n",
        "        h_scaled, w_scaled = int(h*s),int(w*s)\n",
        "        imgx_scaled = cv2.resize(imx[num_slice], (h_scaled,w_scaled), interpolation=cv2.INTER_CUBIC)\n",
        "        imgy_scaled = cv2.resize(imy[num_slice], (h_scaled,w_scaled), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # extract patches\n",
        "        for i in range(0, h_scaled-patch_size+1, stride):\n",
        "            for j in range(0, w_scaled-patch_size+1, stride):\n",
        "                  x_train = imgx_scaled[i:i+patch_size, j:j+patch_size]\n",
        "                  y_train = imgy_scaled[i:i+patch_size, j:j+patch_size]\n",
        "                #print(x.shape)\n",
        "    # data aug\n",
        "                  for k in range(0, aug_times):\n",
        "                      mode=np.random.randint(0,8)                              \n",
        "                      x_aug_train = data_aug(x_train,mode)\n",
        "                      y_aug_train = data_aug(y_train,mode)\n",
        "                      #if np.sum(x_aug_train>0):\n",
        "                      x_patches.append(x_aug_train)\n",
        "                      #if np.sum(y_aug_train>0):\n",
        "                      y_patches.append(y_aug_train)\n",
        "    # save to .npy\n",
        "resx = np.asarray(x_patches)\n",
        "resy = np.asarray(y_patches)\n",
        "\n",
        "print(len(resx))\n",
        "print(len(resy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "197100\n",
            "197100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1E-REsI_G5B"
      },
      "source": [
        "# Save x_train patches\n",
        "save_dir = '.'\n",
        "resx = np.asarray(x_patches)\n",
        "print('Shape of result = ' + str(resx.shape))\n",
        "print('Saving data...')\n",
        "np.save('./x_train_avg4_128_23.npy', resx)\n",
        "print('Done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCkbBdKrGPU6"
      },
      "source": [
        "# Save y_train patches\n",
        "save_dir = '.'\n",
        "resy = np.asarray(y_patches)\n",
        "print('Shape of result = ' + str(resy.shape))\n",
        "print('Saving data...')\n",
        "np.save('./y_train_avg10_128_foravg4_23.npy', resy)\n",
        "print('Done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZsdXu7HByPS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}